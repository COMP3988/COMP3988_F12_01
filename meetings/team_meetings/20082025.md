Wednesday 20 AUG 8:30 PM - 9:30 PM

## Agendas
- Plan slides and complete by tomorrow
- Boilerplate/CI setup this week

###Presentation: 2-3 slides each, 12 slides total, EXCLUDING cover page
Introduction of the project and stakeholders josh 3
Scope of the project (and assumptions/limitations) ariel 2
Timeline in suitable form such as Gantt Chart or table (schedules & group meetings & client interactions) rick 1-2
Responsibility of each member kyrie 2
Expected outcomes and deliverables jason 3

## Official team member roles
These are only our primary roles; we will each take responsibilities across the board.
- **CI/CD/DevOps and Testing** : Jason Liu
- **Team Leader**: Josh
- **Lead Developer**: Rick, Josh
- **Product Owner/ Documentation Lead**: Kyrie
- **R&D/ Data Processing**: Ariel

### Programming pairs/triplets
Jason -> Rick -> Ariel -> Josh -> Kyrie -> Jason 
- Jason reviews Rick's code and so on
- Everytime you log on see if any new code is written by the reviewee using Git Blame in IDE with VSC


## Frameworks and technology
### XP framework
- test cases before code
- since we are working with AI, maybe we should start coding first and then figure out our test cases
- research Jenkins/Github actions for CI
### Technology
- Rick has a 1660 super to train lower-end models. Likely usable for only U-Net. Stronger models requires outsourcing
- Pytorch/MONAI
### Key user stores
- Data preprocessing
- Model Setup
- Training 
- Model Evaluation - Look at evaluation metrics below
- Tweakable parameters (most likely through UI)


## Timeline
W3: Set up CI using Github actions and establish workflow maybe just focus on slides and presentationâ€¦
W4: Image Gen Model runnable via CLI
U-Net or Pix2Pix. Generate images even if random noise.
W5: Front-end encompassing all CLI features.
Parameters (MRI-CT or CBCT-sCT)
W6: Begin creation and training of other models (GAN, Transform, Diffusion..)
No frontend integration yet
W7 (First Delivery): Concrete frontend integration ready for delivery
W8: More advanced GUI features to assist training (preprocessing, parameter tweaking etc)
I.e. allow selection for different models
React Frontend, REST API/ Flask backend
W9: Refine more complex models (GAN)
W10: TBD
W11: TBD
W12 (Final delivery): 

## Metrics
[calculation formulae here](https://synthrad2025.grand-challenge.org/metrics-ranking/)
### Image similarity metrics
**MAE (Mean Absolute Error) and RMSE (Root Mean Square Error)**: Measure pixel-wise intensity differences.
**PSNR (Peak Signal-to-Noise Ratio)**: Indicates noise level and overall image fidelity.
**SSIM (Structural Similarity Index) and variants (e.g., MS-SSIM)**: Evaluate structural and perceptual similarity.

### Anatomical / Structural Accuracy (Geometric Consistency)
The geometric consistency between deformed CT and sCT will be evaluated by analysing the segmentation of anatomical structures. Evaluated using the following, averaged over all structures.
**Dice Similarity Coefficient**: Evaluates overlap for segmented tissues (e.g., bone vs. soft tissue).
**Hausdorff Distance**: Captures maximum spatial deviation between anatomical boundaries.
Other shape/registration-based metrics for alignment and structural fidelity.

### Dosimetric and Clinical Relevance (Dose Evaluation)
**Mean Absolute Dose Differences**: Relative to the prescribed dose.
**DVH (Dose-Volume Histogram) Parameters**: Percent differences (e.g., mean dose deviations in targets and OARs (organ-at-risk)).
**Gamma Index Analysis**: Often using criteria like 1-2mm/1-2% to assess dose distribution agreement


